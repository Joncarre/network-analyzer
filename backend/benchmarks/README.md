# Benchmarks del Network Analyzer

Este directorio contiene una suite completa de benchmarks para medir el rendimiento del Network Analyzer en diferentes aspectos: procesamiento de archivos PCAP, rendimiento de la API REST y operaciones de base de datos.

##  Descripci贸n de los Benchmarks

### 1. Benchmark de Procesamiento PCAP (`benchmark_processing.py`)
- **Prop贸sito**: Mide el rendimiento del procesamiento de archivos PCAP
- **M茅tricas**:
  - Tiempo de procesamiento por archivo
  - Throughput en paquetes por segundo
  - Throughput en MB por segundo
  - Estad铆sticas por m煤ltiples iteraciones

### 2. Benchmark de API REST (`benchmark_api.py`)
- **Prop贸sito**: Eval煤a el rendimiento de los endpoints de la API
- **M茅tricas**:
  - Tiempo de respuesta promedio
  - Requests por segundo (RPS)
  - Tasa de 茅xito
  - Rendimiento bajo carga concurrente

### 3. Benchmark de Base de Datos (`benchmark_database.py`)
- **Prop贸sito**: Mide el rendimiento de las operaciones de base de datos SQLite
- **M茅tricas**:
  - Tiempo de respuesta de queries comunes
  - Rendimiento de operaciones de escritura
  - Throughput de inserci贸n individual vs batch

### 4. Suite Completa (`run_benchmarks.py`)
- **Prop贸sito**: Ejecuta todos los benchmarks y genera gr谩ficos autom谩ticamente
- **Caracter铆sticas**:
  - Ejecuci贸n secuencial de todos los benchmarks
  - Generaci贸n autom谩tica de gr谩ficos de rendimiento
  - Reporte HTML consolidado
  - Configuraci贸n flexible por argumentos

##  Instalaci贸n y Configuraci贸n

### Instalar Dependencias
```bash
# Desde el directorio benchmarks
pip install -r requirements.txt
```

### Dependencias Principales
- `matplotlib`: Generaci贸n de gr谩ficos
- `pandas`: Manipulaci贸n de datos
- `seaborn`: Visualizaciones estad铆sticas
- `numpy`: C谩lculos num茅ricos
- `requests`: Pruebas de API

##  Uso de los Benchmarks

### Ejecutar Suite Completa (Recomendado)
```bash
# Ejecutar todos los benchmarks con configuraci贸n por defecto
python run_benchmarks.py

# Con par谩metros personalizados
python run_benchmarks.py --processing-iterations 5 --api-url http://localhost:8000 --db-iterations 15

# Saltar benchmarks espec铆ficos
python run_benchmarks.py --skip-api --skip-database
```

### Ejecutar Benchmarks Individuales

#### Benchmark de Procesamiento
```bash
# Con 3 iteraciones por defecto
python benchmark_processing.py

# Con n煤mero personalizado de iteraciones
python benchmark_processing.py 5
```

#### Benchmark de API
```bash
# Con URL por defecto (localhost:8000)
python benchmark_api.py

# Con URL personalizada
python benchmark_api.py http://192.168.1.100:8000
```

#### Benchmark de Base de Datos
```bash
# Con 10 iteraciones por defecto
python benchmark_database.py

# Con n煤mero personalizado de iteraciones
python benchmark_database.py 20
```

##  Estructura de Resultados

Los benchmarks generan varios tipos de archivos de salida:

### Archivos JSON de Resultados
- `benchmark_processing_YYYYMMDD_HHMMSS.json`
- `benchmark_api_YYYYMMDD_HHMMSS.json`
- `benchmark_database_YYYYMMDD_HHMMSS.json`

### Gr谩ficos Generados (directorio `results/`)
- `processing_throughput.png`: Throughput de procesamiento PCAP
- `processing_time_vs_size.png`: Relaci贸n tiempo vs tama帽o de archivo
- `api_performance.png`: Tiempos de respuesta y tasas de 茅xito de API
- `api_rps.png`: Requests por segundo por endpoint
- `database_query_performance.png`: Rendimiento de queries de DB
- `database_write_performance.png`: Rendimiento de escritura en DB

### Reporte HTML
- `results/benchmark_report.html`: Reporte consolidado con todas las m茅tricas y gr谩ficos

##  Requisitos Previos

### Para Benchmark de Procesamiento
- Archivos PCAP en `../data/pcap_files/`
- M贸dulo `PCAPProcessor` funcional

### Para Benchmark de API
- Servidor backend ejecut谩ndose (por defecto en puerto 8000)
- Endpoints de API accesibles

### Para Benchmark de Base de Datos
- Archivos de base de datos SQLite en `../data/databases/`
- Esquema de BD compatible con las queries de prueba

##  Interpretaci贸n de Resultados

### M茅tricas de Procesamiento
- **Throughput alto**: Mejor rendimiento en el procesamiento de paquetes
- **Tiempo vs Tama帽o**: Relaci贸n lineal indica escalabilidad predecible
- **Consistencia**: Baja desviaci贸n est谩ndar indica rendimiento estable

### M茅tricas de API
- **Tiempo de respuesta bajo**: Mejor experiencia de usuario
- **RPS alto**: Mayor capacidad de carga
- **Tasa de 茅xito 100%**: Estabilidad de la API

### M茅tricas de Base de Datos
- **Queries r谩pidas**: Mejor responsividad de la aplicaci贸n
- **Escritura eficiente**: Importante para captura en tiempo real
- **Escalabilidad**: Rendimiento constante con diferentes tama帽os de BD

##  Casos de Uso

### Desarrollo y Optimizaci贸n
- Identificar cuellos de botella en el rendimiento
- Comparar el impacto de cambios de c贸digo
- Validar optimizaciones

### Testing de Carga
- Verificar rendimiento bajo diferentes cargas de trabajo
- Planificar capacidad de hardware
- Establecer SLAs (Service Level Agreements)

### Monitoreo Continuo
- Detectar regresiones de rendimiento
- Mantener hist贸rico de m茅tricas
- Benchmarking antes de releases

##  Troubleshooting

### Errores Comunes

#### "No se encontraron archivos PCAP"
- Verificar que exista el directorio `../data/pcap_files/`
- Colocar archivos .pcap o .pcapng en el directorio

#### "API no disponible"
- Verificar que el backend est茅 ejecut谩ndose
- Comprobar la URL y puerto correctos
- Verificar conectividad de red

#### "Error de importaci贸n de matplotlib"
- Instalar dependencias: `pip install -r requirements.txt`
- En algunas distribuciones Linux: `sudo apt-get install python3-tk`

#### "Permisos de escritura"
- Verificar permisos en el directorio actual
- El script necesita crear archivos JSON y el directorio `results/`

### Optimizaci贸n de Rendimiento
- Usar SSD para mejor I/O de base de datos
- Aumentar RAM disponible para procesamiento de archivos grandes
- Considerar paralelizaci贸n para m煤ltiples archivos PCAP

##  Extensi贸n de Benchmarks

Para agregar nuevos benchmarks:

1. Crear nuevo archivo `benchmark_[nombre].py`
2. Seguir la estructura de los benchmarks existentes
3. Implementar m茅todos de medici贸n y guardado de resultados
4. Agregar integraci贸n en `run_benchmarks.py`
5. Actualizar este README

### Ejemplo de Estructura de Benchmark
```python
class NewBenchmark:
    def __init__(self):
        self.results = []
    
    def benchmark_operation(self, iterations=10):
        # Implementar medici贸n
        pass
    
    def run_benchmark(self):
        # Ejecutar todas las pruebas
        pass
    
    def save_results(self):
        # Guardar en JSON con timestamp
        pass
    
    def print_summary(self):
        # Mostrar resumen en consola
        pass
```

##  Soporte

Para problemas espec铆ficos con los benchmarks:
1. Verificar los logs de salida de cada script
2. Comprobar que todos los prerequisitos est茅n instalados
3. Validar que los datos de prueba est茅n disponibles
4. Revisar los archivos JSON de resultados para m谩s detalles

---

**Nota**: Los benchmarks est谩n dise帽ados para ser no intrusivos y usar las APIs existentes del proyecto sin modificar el c贸digo principal.
